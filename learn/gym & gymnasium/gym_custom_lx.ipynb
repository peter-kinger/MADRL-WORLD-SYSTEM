{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gym 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    自定义的Gym环境模板。\n",
    "    这个环境模拟了一个简单的系统，其中代理可以执行一个动作来改变系统的状态，并根据状态的变化获取奖励。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        \n",
    "        # 定义动作空间，假设这里的动作是一个单维的连续变量，范围从-1到1\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        \n",
    "        # 定义状态空间，假设状态是一个二维的连续变量，范围从0到100\n",
    "        self.observation_space = spaces.Box(low=0, high=100, shape=(2,), dtype=np.float32)\n",
    "        \n",
    "        # 初始化环境状态\n",
    "        self.state = np.zeros(2)\n",
    "        self.steps = 0\n",
    "        self.max_steps = 100  # 限制最大步数\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        在每次新回合开始时重置环境状态。\n",
    "        返回初始状态。\n",
    "        \"\"\"\n",
    "        self.state = np.array([50, 50])  # 初始化为中间值\n",
    "        self.steps = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        在环境中执行一个动作，并返回新的状态、奖励、是否结束和其他信息。\n",
    "        参数:\n",
    "        - action: 代理采取的动作\n",
    "        \n",
    "        返回:\n",
    "        - state: 新的状态\n",
    "        - reward: 根据新状态计算的奖励\n",
    "        - done: 布尔值，指示回合是否结束\n",
    "        - info: 额外信息，通常用于调试\n",
    "        \"\"\"\n",
    "        # 更新状态，根据动作和当前状态进行计算\n",
    "        self.state = self.state + action  # 简单线性模型\n",
    "        \n",
    "        # 确保状态在定义的范围内\n",
    "        self.state = np.clip(self.state, 0, 100)\n",
    "        \n",
    "        # 增加步数计数器\n",
    "        self.steps += 1\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gymnasium 版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html\n",
    "来自官网要求\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self, arg1, arg2, ...):\n",
    "        super().__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)\n",
    "        # Example for using image as input (channel-first; channel-last also works):\n",
    "        self.observation_space = spaces.Box(low=0, high=255,\n",
    "                                            shape=(N_CHANNELS, HEIGHT, WIDTH), dtype=np.uint8)\n",
    "\n",
    "    def step(self, action):\n",
    "        ...\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        ...\n",
    "        return observation, info\n",
    "\n",
    "    def render(self):\n",
    "        ...\n",
    "\n",
    "    def close(self):\n",
    "        ..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
